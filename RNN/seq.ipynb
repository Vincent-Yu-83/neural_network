{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from tools import tool_pytorch_017 as ty\n",
    "\n",
    "'''\n",
    "创建一个1000个点的集合，从1开始，一直到1000，作为一个连续的序列\n",
    "'''\n",
    "\n",
    "T = 1000  # 总共产生1000个点\n",
    "time = torch.arange(1, T + 1, dtype=torch.float32)\n",
    "#在序列中加入噪声数据，具体是加入均值为0方差为0.2的数据\n",
    "x = torch.sin(0.01 * time) + torch.normal(0, 0.2, (T,))\n",
    "ty.plot(time, [x], 'time', 'x', xlim=[1, 1000], figsize=(6, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置tau为4，也就是说以当前元素的前四个元素为学习依据\n",
    "tau = 4\n",
    "features = torch.zeros((T - tau, tau))\n",
    "for i in range(tau):\n",
    "    # 从x中取出下标数据作为特征集\n",
    "    features[:, i] = x[i: T - tau + i]\n",
    "# 取出tau后的一个数据，作为值\n",
    "labels = x[tau:].reshape((-1, 1))\n",
    "\n",
    "\n",
    "# 初始化网络权重的函数\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "# 一个简单的多层感知机\n",
    "def get_net():\n",
    "    net = nn.Sequential(nn.Linear(4, 10),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(10, 1))\n",
    "    net.apply(init_weights)\n",
    "    return net\n",
    "\n",
    "# 平方损失。注意：MSELoss计算平方误差时不带系数1/2\n",
    "loss = nn.MSELoss(reduction='none')\n",
    "\n",
    "def train(net, train_iter, loss, epochs, lr):\n",
    "    trainer = torch.optim.Adam(net.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            l = loss(net(X), y)\n",
    "            l.sum().backward()\n",
    "            trainer.step()\n",
    "        print(f'epoch {epoch + 1}, '\n",
    "              f'loss: {ty.evaluate_loss(net, train_iter, loss):f}')\n",
    "\n",
    "batch_size, n_train = 16, 600\n",
    "# 只有前n_train个样本用于训练\n",
    "train_iter = ty.load_array((features[:n_train], labels[:n_train]),\n",
    "                            batch_size, is_train=True)\n",
    "net = get_net()\n",
    "train(net, train_iter, loss, 5, 0.01)\n",
    "\n",
    "# 开始单步预测，也就是说每次只位移一个元素\n",
    "# 我们训练的次数为600，也就是说我们单步预测只向前位移了604个元素\n",
    "# 但604个元素以后的预测结果也是不错的\n",
    "onestep_preds = net(features)\n",
    "ty.plot([time, time[tau:]],\n",
    "         [x.detach().numpy(), onestep_preds.detach().numpy()], 'time',\n",
    "         'x', legend=['data', '1-step preds'], xlim=[1, 1000],\n",
    "         figsize=(6, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行多步预测，多步预测将从第604个元素起使用自己的数据来做\n",
    "# 这里是初始化成0了\n",
    "# 效果可想而知，预测结果接近-0.1\n",
    "multistep_preds = torch.zeros(T)\n",
    "multistep_preds[: n_train + tau] = x[: n_train + tau]\n",
    "for i in range(n_train + tau, T):\n",
    "    multistep_preds[i] = net(\n",
    "        multistep_preds[i - tau:i].reshape((1, -1)))\n",
    "\n",
    "ty.plot([time, time[tau:], time[n_train + tau:]],\n",
    "         [x.detach().numpy(), onestep_preds.detach().numpy(),\n",
    "          multistep_preds[n_train + tau:].detach().numpy()], 'time',\n",
    "         'x', legend=['data', '1-step preds', 'multistep preds'],\n",
    "         xlim=[1, 1000], figsize=(6, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过对整个序列预测的计算， 让我们更仔细地看一下每次位移1、4、16、64步预测的困难。\n",
    "max_steps = 64\n",
    "\n",
    "features = torch.zeros((T - tau - max_steps + 1, tau + max_steps))\n",
    "# 列i（i<tau）是来自x的观测，其时间步从（i）到（i+T-tau-max_steps+1）\n",
    "for i in range(tau):\n",
    "    features[:, i] = x[i: i + T - tau - max_steps + 1]\n",
    "\n",
    "# 列i（i>=tau）是来自（i-tau+1）步的预测，其时间步从（i）到（i+T-tau-max_steps+1）\n",
    "for i in range(tau, tau + max_steps):\n",
    "    features[:, i] = net(features[:, i - tau:i]).reshape(-1)\n",
    "\n",
    "steps = (1, 4, 16, 64)\n",
    "ty.plot([time[tau + i - 1: T - max_steps + i] for i in steps],\n",
    "         [features[:, (tau + i - 1)].detach().numpy() for i in steps], 'time', 'x',\n",
    "         legend=[f'{i}-step preds' for i in steps], xlim=[5, 1000],\n",
    "         figsize=(6, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
