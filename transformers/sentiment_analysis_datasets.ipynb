{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from tools import tool_pytorch_017 as ty\n",
    "\n",
    "#@save\n",
    "ty.DATA_HUB['aclImdb'] = (\n",
    "    'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz',\n",
    "    '01ada507287d82875905620988597833ad4e0903')\n",
    "\n",
    "data_dir = ty.download_extract('aclImdb', 'aclImdb')\n",
    "\n",
    "#@save\n",
    "def read_imdb(data_dir, is_train):\n",
    "    \"\"\"读取IMDb评论数据集文本序列和标签\"\"\"\n",
    "    data, labels = [], []\n",
    "    for label in ('pos', 'neg'):\n",
    "        folder_name = os.path.join(data_dir, 'train' if is_train else 'test',\n",
    "                                   label)\n",
    "        for file in os.listdir(folder_name):\n",
    "            with open(os.path.join(folder_name, file), 'rb') as f:\n",
    "                review = f.read().decode('utf-8').replace('\\n', '')\n",
    "                data.append(review)\n",
    "                labels.append(1 if label == 'pos' else 0)\n",
    "    return data, labels\n",
    "\n",
    "train_data = read_imdb(data_dir, is_train=True)\n",
    "print('训练集数目：', len(train_data[0]))\n",
    "for x, y in zip(train_data[0][:3], train_data[1][:3]):\n",
    "    print('标签：', y, 'review:', x[0:60])\n",
    "    \n",
    "# 将每个单词作为一个词元，过滤掉出现不到5次的单词，我们从训练数据集中创建一个词表。\n",
    "train_tokens = ty.tokenize(train_data[0], token='word')\n",
    "vocab = ty.Vocab(train_tokens, min_freq=5, reserved_tokens=['<pad>'])\n",
    "\n",
    "ty.set_figsize()\n",
    "ty.plt.xlabel('# tokens per review')\n",
    "ty.plt.ylabel('count')\n",
    "ty.plt.hist([len(line) for line in train_tokens], bins=range(0, 1000, 50));\n",
    "\n",
    "# 为了每次处理一小批量这样的评论，我们通过截断和填充将每个评论的长度设置为500。\n",
    "num_steps = 500  # 序列长度\n",
    "train_features = torch.tensor([ty.truncate_pad(\n",
    "    vocab[line], num_steps, vocab['<pad>']) for line in train_tokens])\n",
    "print(train_features.shape)\n",
    "\n",
    "train_iter = ty.load_array((train_features,\n",
    "    torch.tensor(train_data[1])), 64)\n",
    "\n",
    "for X, y in train_iter:\n",
    "    print('X:', X.shape, ', y:', y.shape)\n",
    "    break\n",
    "print('小批量数目：', len(train_iter))\n",
    "\n",
    "#@save\n",
    "def load_data_imdb(batch_size, num_steps=500):\n",
    "    \"\"\"返回数据迭代器和IMDb评论数据集的词表\"\"\"\n",
    "    data_dir = ty.download_extract('aclImdb', 'aclImdb')\n",
    "    train_data = read_imdb(data_dir, True)\n",
    "    test_data = read_imdb(data_dir, False)\n",
    "    train_tokens = ty.tokenize(train_data[0], token='word')\n",
    "    test_tokens = ty.tokenize(test_data[0], token='word')\n",
    "    vocab = ty.Vocab(train_tokens, min_freq=5)\n",
    "    train_features = torch.tensor([ty.truncate_pad(\n",
    "        vocab[line], num_steps, vocab['<pad>']) for line in train_tokens])\n",
    "    test_features = torch.tensor([ty.truncate_pad(\n",
    "        vocab[line], num_steps, vocab['<pad>']) for line in test_tokens])\n",
    "    train_iter = ty.load_array((train_features, torch.tensor(train_data[1])),\n",
    "                                batch_size)\n",
    "    test_iter = ty.load_array((test_features, torch.tensor(test_data[1])),\n",
    "                               batch_size,\n",
    "                               is_train=False)\n",
    "    return train_iter, test_iter, vocab\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
